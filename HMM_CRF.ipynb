{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>Speech & Natural Language Processing</center>\n",
    "#  <center>Assignment 2 : Sequence Labelling Models</center>\n",
    "## Suyash Damle\n",
    "## 15CS10057"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Q1: Discriminative vs Generative Models\n",
    "***\n",
    "#### A classification model is said to be Discriminative if it tries to learn and maximize the probability: P(y | x). It takes an input and outputs a classification according to above principle. Classifiers *not* working with probability, but doing similar tasks (such as neural nets) are also loosely called discriminative.\n",
    "\n",
    "\n",
    "#### On the other hand,  a generative model learns the probability:  P(x, y). It could start generating output from a single or no input, by assuming a default state.\n",
    "\n",
    "#### So :\n",
    "\n",
    "- #### Neural Net:  Discriminative\n",
    "- #### SVM : Discriminative\n",
    "- #### Logistic Regressor : Discriminative\n",
    "- #### Naive Bayes: Discriminative\n",
    "- #### LDA : Generative\n",
    "- #### Gaussian Mixture Model: Generative\n",
    "- #### Decision Tree : Discriminative\n",
    "- #### GANs : Generative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk import bigrams, ngrams, trigrams \n",
    "import re\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import accuracy_score #just to calculate the accuracy score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57240\n",
      "100\n",
      "[[(None, 'START'), ('In', 'ADP'), ('this', 'DET'), ('work', 'NOUN'), (',', '.'), ('his', 'DET'), ('use', 'NOUN'), ('of', 'ADP'), ('non-color', 'NOUN'), ('is', 'VERB'), ('startling', 'ADJ'), ('and', 'CONJ'), ('skillful', 'ADJ'), ('.', '.')], [(None, 'START'), ('The', 'DET'), ('sweep', 'NOUN'), ('of', 'ADP'), ('space', 'NOUN'), (',', '.'), ('the', 'DET'), ('delicate', 'ADJ'), ('counterbalance', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('white', 'ADJ'), ('masses', 'NOUN'), (',', '.'), ('the', 'DET'), ('over-all', 'ADJ'), ('completeness', 'NOUN'), ('and', 'CONJ'), ('unity', 'NOUN'), (',', '.'), ('the', 'DET'), ('originality', 'NOUN'), ('and', 'CONJ'), ('imagination', 'NOUN'), (',', '.'), ('all', 'PRT'), ('entitle', 'VERB'), ('it', 'PRON'), ('to', 'PRT'), ('be', 'VERB'), ('called', 'VERB'), ('an', 'DET'), ('authentic', 'ADJ'), ('masterpiece', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "sents=brown.tagged_sents(tagset='universal')\n",
    "sents=[sentence for sentence in sents]  # the entire corpus - sentences as collection of (words,tags). The NLTK...\n",
    "                                        # ...  list types are custom \"lazy\" types and could not be directly edited\n",
    "sents_train=sents[:-100]\n",
    "sents_test=sents[-100:]\n",
    "for sentence in sents_train:\n",
    "    sentence.insert(0,(None,'START'))\n",
    "    #sentence.append((None,'END'))\n",
    "print (len(sents_train))\n",
    "print (len(sents_test))\n",
    "print (sents_train[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating required data collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict={}\n",
    "tag_dict={}\n",
    "tag_bigram_dict={}\n",
    "tag_obs_dict={}\n",
    "for sentence in sents_train:\n",
    "    for x in sentence:\n",
    "        word=x[0]\n",
    "        tag=x[1]\n",
    "        if word not in word_dict:\n",
    "            word_dict[word]=0\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=0\n",
    "        if (tag,word) not in tag_obs_dict:\n",
    "            tag_obs_dict[(tag,word)]=0\n",
    "            \n",
    "        word_dict[word]+=1\n",
    "        tag_dict[tag]+=1\n",
    "        tag_obs_dict[(tag,word)]+=1\n",
    "\n",
    "    for x in nltk.bigrams(sentence):\n",
    "        tag1=x[0][1]\n",
    "        tag2=x[1][1]\n",
    "        if (tag1,tag2)not in tag_bigram_dict:\n",
    "            tag_bigram_dict[(tag1,tag2)]=0\n",
    "            \n",
    "        tag_bigram_dict[(tag1,tag2)]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***\n",
    "## Q2 : The HMM Model\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating function to train the HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "tag_bigram_counts={}\n",
    "tag_obs_counts={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmm(k=1):\n",
    "    # uses Laplacian Smoothing with the parameter k supplied\n",
    "    # needs the data created in previous stage\n",
    "    global tag_bigram_counts,tag_obs_counts\n",
    "    \n",
    "    states_size=len(tag_dict)\n",
    "    vocab_size=len(word_dict)\n",
    "    tag_bigram_dict_new=tag_bigram_dict.copy()\n",
    "    tag_obs_dict_new=tag_obs_dict.copy()\n",
    "\n",
    "    \n",
    "    for token in tag_bigram_dict_new:\n",
    "        t1=token[0]\n",
    "        if t1 not in tag_bigram_counts:\n",
    "            tag_bigram_counts[t1]=0\n",
    "        tag_bigram_counts[t1]+=tag_bigram_dict_new[token]\n",
    "        \n",
    "    for token in tag_obs_dict_new:\n",
    "        t1=token[0]\n",
    "        if t1 not in tag_obs_counts:\n",
    "            tag_obs_counts[t1]=0\n",
    "        tag_obs_counts[t1]+=tag_obs_dict_new[token]\n",
    "        \n",
    "        \n",
    "    for token in tag_bigram_dict_new:\n",
    "        t1=token[0]\n",
    "        tag_bigram_dict_new[token]+=k\n",
    "        tag_bigram_dict_new[token]/=(float(tag_bigram_counts[t1])+k*states_size)\n",
    "        if tag_bigram_dict_new[token]>1:\n",
    "            print(token, tag_bigram_dict_new[token])\n",
    "    tag_bigram_dict_new['DEFAULT_VAL']=1.0/states_size\n",
    "        \n",
    "    for token in tag_obs_dict_new:\n",
    "        t1=token[0]\n",
    "        t2=token[1]\n",
    "        tag_obs_dict_new[(t1,t2)]+=k\n",
    "        tag_obs_dict_new[(t1,t2)]/=(float(tag_obs_counts[t1])+k*states_size)\n",
    "    tag_obs_dict_new['DEFAULT_VAL']=1.0/states_size\n",
    "        \n",
    "    return tag_bigram_dict_new,tag_obs_dict_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to test HMM using Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_predict(trans_prob,obs_prob,string,k=1):\n",
    "    '''\n",
    "    trans_prob: the dict of <state_i, state_j> tuples\n",
    "    obs_prob: the dict of <state, observation> tuples\n",
    "    string: a list of words of the required sentence in the right order\n",
    "    '''\n",
    "    states_size=len(tag_dict)\n",
    "    vocab_size=len(word_dict)\n",
    "    tags_list=list(tag_dict.keys())\n",
    "    mat=np.zeros((len(string),states_size))\n",
    "    mat_backtrack=np.zeros((len(string),states_size))\n",
    "    \n",
    "    #### initialization phase - for size=0 row ##########\n",
    "    for idx in range(states_size):\n",
    "        tuple1=('START',tags_list[idx])\n",
    "        tuple2=(tags_list[idx],string[0])\n",
    "        tr_prob=0.\n",
    "        ob_prob=0.\n",
    "        if tuple1 in trans_prob:\n",
    "            tr_prob=trans_prob[tuple1]\n",
    "        else:\n",
    "            tr_prob=0.\n",
    "            \n",
    "        if tuple2 in obs_prob:\n",
    "            ob_prob=obs_prob[tuple2]\n",
    "        else:\n",
    "            ob_prob=(1.0*k)/(tag_obs_counts[tags_list[idx]]+k*states_size)\n",
    "        \n",
    "    \n",
    "        mat[0][idx]=np.log2(tr_prob*ob_prob)\n",
    "        mat_backtrack[0][idx]=tags_list.index('START')\n",
    "    ####################################################\n",
    "    \n",
    "    #### Dynamic Programming phase begins here ##########\n",
    "    for str_idx in range(1,len(string)):\n",
    "        for state_idx_l,state_l in enumerate(tags_list):  # future state - l\n",
    "            max_val=-1*np.inf\n",
    "            max_val_state=-1\n",
    "            for state_idx_k,state_k in enumerate(tags_list):  # prev. state - k\n",
    "                term1=mat[str_idx-1][state_idx_k]\n",
    "                term2=0.\n",
    "                term3=0.\n",
    "                \n",
    "                if (state_k,state_l) in trans_prob:\n",
    "                    term2=trans_prob[(state_k,state_l)]\n",
    "                else:\n",
    "                    term2=(k*1.)/(tag_bigram_counts[state_k]+k*states_size)\n",
    "                    \n",
    "                if(state_l,string[str_idx]) in obs_prob:\n",
    "                    term3=obs_prob[(state_l,string[str_idx])]\n",
    "                else:\n",
    "                    term3=(k*1.)/(tag_obs_counts[state_k]+k*states_size)\n",
    "                    \n",
    "                term_final=term1+np.log2(term2)+np.log2(term3)\n",
    "                \n",
    "                if term_final > max_val:\n",
    "                    max_val=term_final\n",
    "                    max_val_state=state_idx_k\n",
    "                    \n",
    "            mat[str_idx][state_idx_l]=max_val\n",
    "            mat_backtrack[str_idx][state_idx_l]=max_val_state\n",
    "    #########################################################\n",
    "    \n",
    "    \n",
    "    #### Back-Tracking from here #############################\n",
    "    # the final state is being taken as implicit\n",
    "    \n",
    "    tags_sequence=[]\n",
    "    this_state_idx=np.argmax(mat[len(string)-1])\n",
    "    this_state_val=tags_list[this_state_idx]\n",
    "    tags_sequence.insert(0,this_state_val)\n",
    "    prev_state_idx=mat_backtrack[len(string)-1][this_state_idx]\n",
    "    for str_idx in range(len(string)-2,-1,-1):\n",
    "        this_state_val=tags_list[int(prev_state_idx)]\n",
    "        tags_sequence.insert(0,this_state_val)\n",
    "        prev_state_idx=mat_backtrack[str_idx][int(prev_state_idx)]\n",
    "        \n",
    "    return tags_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The controller function for the HMM training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_hmm(k_val=1):\n",
    "    '''\n",
    "    The main controller function\n",
    "    '''\n",
    "    np.seterr(divide='ignore')\n",
    "    k=k_val\n",
    "    trans_prob, obs_prob=train_hmm(k=k)\n",
    "    true_tag=[]\n",
    "    predicted_tags=[]\n",
    "    for sentence in sents_test:\n",
    "        test_sentence=[]\n",
    "        for token in sentence:\n",
    "            test_sentence.append(token[0])\n",
    "            true_tag.append(token[1])\n",
    "        pred_tags=viterbi_predict(trans_prob,obs_prob,test_sentence,k=k)\n",
    "        predicted_tags.extend(pred_tags)\n",
    "    accuracy=accuracy_score(true_tag,predicted_tags)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9332213355732886\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_vals=[0.0001,0.001,0.01,0.1]\n",
    "accuracy_scores=[]\n",
    "for k_val in k_vals:\n",
    "    accuracy_scores.append(driver_hmm(k_val=k_val))\n",
    "    \n",
    "plt.plot(k_vals,accuracy_scores)\n",
    "plt.xlabel('laplacian smoothing parameter')\n",
    "plt.ylabel('accuracies')\n",
    "plt.show\n",
    "\n",
    "print(accuracy_scores[0]) # printing the best value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Q 3 : The CRF model\n",
    "***\n",
    "\n",
    "\n",
    "#### The following features are added : \n",
    "\n",
    "- *prefix-1, prefix-2, prefix-3* :  The prefix upto the stated length of the word. Appearance of modifiers in the prefix, such as \"un-\"(as in uncomfortable) or \"a-\" (as in asymmetrical) or \"pre-\", etc often indicate **Adjective** or **Adverbs**\n",
    "\n",
    "\n",
    "- *suffix-1, suffix-2, suffix-3* : For the same reason as above - presence of suffixes could indicate different POSs: eg: \"-ity\" as in \"inactivity\" indicates **Noun**, \"-ness\" as in \"sadness\" indicates **Adjective**\n",
    "\n",
    "\n",
    "- *is_first* : Whether the word is the first word in the sentence. First words in english are usually **Nouns or Pronouns or Determinants**\n",
    "\n",
    "\n",
    "- *is_last* : Sentences usually end with object of the verb; ie, they are likely to be **Nouns**\n",
    "\n",
    "\n",
    "- *is_upper* : Whether the word is in uppercase. Would indicate acronyms - usually **Nouns**\n",
    "\n",
    "\n",
    "- *is_title* : Whether first letter is capitalized. Indicates either beginning of sentence or **Proper Noun**\n",
    "\n",
    "\n",
    "- *is_digit* : Universal Tagset has **NUM** tag for numerical data\n",
    "\n",
    "\n",
    "- *prev-1* : The previous word (if existent). The preceding word could be very helpful in determining this word's tag: an article could indicate the beginning of a noun phrase. So, this word is likely to be **Noun or Adjective or Pronoun**\n",
    "\n",
    "\n",
    "- *prev-1_is_title* :  Whether the previous word has capitalized first letter\n",
    "\n",
    "\n",
    "- *prev-1_is_upper, prev-1_is_digit* : Whether the previous words is in uppercase / is numerical.\n",
    "\n",
    "\n",
    "- *next-1, and its features* : The very next word. As before, the next word and its features are helpful.\n",
    "\n",
    "- *next-2  &  prev-2* : The next-to-next  and the prev-to-prev  terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_features(sent,idx,features_list=None, bias=1.):\n",
    "    word=sent[idx]\n",
    "    \n",
    "    #The list of all available features. These would be added one-by-one to test their effectiveness\n",
    "    all_features={\n",
    "        'bias':bias,\n",
    "        'word':word.lower(),\n",
    "        'prefix-1': word.lower()[0],\n",
    "        'prefix-2': word.lower()[:2],\n",
    "        'prefix-3': word.lower()[:3],\n",
    "        'suffix-1': word.lower()[-1],\n",
    "        'suffix-2': word.lower()[-2:],\n",
    "        'suffix-3': word.lower()[-3:],\n",
    "        'is_first': idx==0,\n",
    "        'is_last' : idx==len(sent)-1,\n",
    "        'is_upper': word.isupper(),\n",
    "        'is_title': word.istitle(),\n",
    "        'is_digit': word.isdigit(),\n",
    "        'prev-2':sent[idx-2].lower() if idx>1 else '',\n",
    "        'next-2':sent[idx+2].lower() if idx<len(sent)-2 else ''\n",
    "    }\n",
    "    \n",
    "    # features corresponding to prev word\n",
    "    if idx>0:\n",
    "        word_prev=sent[idx-1]\n",
    "        all_features.update({\n",
    "            'prev-1': word_prev,\n",
    "            'prev-1_is_title':word_prev.istitle(),\n",
    "            'prev-1_is_upper':word_prev.isupper(),\n",
    "            'prev-1_is_digit':word_prev.isdigit(),\n",
    "        })\n",
    "        \n",
    "    # features of the next word\n",
    "    if idx<len(sent)-1:\n",
    "        word_next=sent[len(sent)-1]\n",
    "        all_features.update({\n",
    "            'next-1': word_next,\n",
    "            'next-1_is_title':word_next.istitle(),\n",
    "            'next-1_is_upper':word_next.isupper(),\n",
    "            'next-1_is_digit':word_next.isdigit(),\n",
    "        })\n",
    "        \n",
    "    if features_list is not None:\n",
    "        # selectively add features and return those\n",
    "        new_features={}\n",
    "        new_features['bias']=all_features['bias']  #default feature\n",
    "        new_features['word']=all_features['word']  #default feature\n",
    "        for feat  in features_list:\n",
    "            if feat in all_features:\n",
    "                new_features[feat]=all_features[feat]\n",
    "        \n",
    "        return new_features\n",
    "        \n",
    "    return all_features\n",
    "\n",
    "def sent_features(sent,features=None):    \n",
    "    '''\n",
    "    Returns the set of features for this sentence\n",
    "    '''\n",
    "    sentence=[]\n",
    "    for idx,(word,tag) in enumerate(sent):\n",
    "        if word is None:\n",
    "            continue\n",
    "        sentence.append(word)\n",
    "    return [word_features(sentence,i,features_list=features) for i in range(len(sentence))]\n",
    "\n",
    "def sent_labels(sent):\n",
    "    '''\n",
    "    Returns the lables sequence for this sentence\n",
    "    '''\n",
    "    pos_tags=[]\n",
    "    for idx,(word,tag) in enumerate(sent):\n",
    "        if word is None:\n",
    "            continue\n",
    "        pos_tags.append(tag)\n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of the fact that each of the stated feature adds some accuracy to the model: \n",
    "\n",
    "\n",
    "***\n",
    "- #### We would incrementaly add certain sets of features and find their effect on the performance wrt the base / previous models. \n",
    "- #### In the interest of quicker checking, *we could reduce the training sample* and work with smaller sets. Only relative performances would then be considered.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function to help with the testing of incremental addition of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crf_feature_test(features,c1=0.1,c2=0.1,limit=20000):\n",
    "    LIMIT=limit # working with only 'LIMIT' no. of training samples\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "\n",
    "    X_train=(sent_features(s,features) for s in sents_train[:LIMIT])\n",
    "    X_test=(sent_features(s,features) for s in sents_test)\n",
    "    y_train=[sent_labels(s) for s in sents_train[:LIMIT]]\n",
    "    y_test=[sent_labels(s) for s in sents_test]\n",
    "\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=c1,\n",
    "        c2=c2,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "    crf.fit(X_train, y_train)\n",
    "    y_pred=crf.predict(X_test)\n",
    "\n",
    "    labels=crf.classes_\n",
    "    accuracy=metrics.flat_accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    return accuracy,y_test,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Testing feature sets incrementally: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 0 : The base model - only the bias and word itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9307013859722806\n"
     ]
    }
   ],
   "source": [
    "accuracy_0,_,_=crf_feature_test([])\n",
    "print(accuracy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 1 : Adding : *Prefix & Suffix* Features to the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9449811003779924\n"
     ]
    }
   ],
   "source": [
    "features=['prefix-1','prefix-2','prefix-3','suffix-1','suffix-2','suffix-3']\n",
    "accuracy_1,_,_=crf_feature_test(features)\n",
    "print(accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 2 :  Adding : *is_first,  is_last,  is_digit,  is_upper,  is_title *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9458210835783284\n"
     ]
    }
   ],
   "source": [
    "features=['prefix-1','prefix-2','prefix-3','suffix-1','suffix-2','suffix-3','is_first','is_last','is_digit','is_upper','is_title']\n",
    "accuracy_2,_,_=crf_feature_test(features)\n",
    "print(accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 3 : Adding: *prev-1,  prev-1_is_upper,  prev-1_is_digit,  prev-1_is_title*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9517009659806804\n"
     ]
    }
   ],
   "source": [
    "features=['prefix-1','prefix-2','prefix-3','suffix-1','suffix-2','suffix-3','is_first','is_last','is_digit',\n",
    "          'is_upper','is_title','prev-1','prev-1_is_digit','prev-1_is_title','prev-1_is_upper']\n",
    "accuracy_3,_,_=crf_feature_test(features)\n",
    "print(accuracy_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 4 : Adding:  *next-1, next-1_is_digit,  next-1_is_upper,  next-1_is_title  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525409491810164\n"
     ]
    }
   ],
   "source": [
    "features=['prefix-1','prefix-2','prefix-3','suffix-1','suffix-2','suffix-3','is_first','is_last','is_digit',\n",
    "          'is_upper','is_title','prev-1','prev-1_is_digit','prev-1_is_title','prev-1_is_upper',\n",
    "         'next-1','next-1_is_digit','next-1_is_title','next-1_is_upper']\n",
    "accuracy_4,_,_=crf_feature_test(features)\n",
    "print(accuracy_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 5 : Adding : *next-2,  prev-2* : ie, next-to-next  & prev-to-prev words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9538009239815204\n"
     ]
    }
   ],
   "source": [
    "features=['prefix-1','prefix-2','prefix-3','suffix-1','suffix-2','suffix-3','is_first','is_last','is_digit',\n",
    "          'is_upper','is_title','prev-1','prev-1_is_digit','prev-1_is_title','prev-1_is_upper',\n",
    "         'next-1','next-1_is_digit','next-1_is_title','next-1_is_upper','prev-2','next-2']\n",
    "accuracy_5,_,_=crf_feature_test(features)\n",
    "print(accuracy_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "***\n",
    "- #### We could clearly see that as more sets of specific features are added, the accuracy (& hence, its performance) increases\n",
    "\n",
    "- #### The overall variation might depend on the way the features are incrementally added; however, the fact remains that adding these features does help the model\n",
    "***\n",
    "\n",
    "\n",
    "### Checking best values of L1 & L2 smoothing parameters:\n",
    "\n",
    "- #### As before, we would run the process on a small train set (10k) for different values of c1 and c2 individually and do a *grid search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 =  0.0001 ; c2 =  0.0001  : accuracy =  0.9399412011759765\n",
      "c1 =  0.0001 ; c2 =  0.001  : accuracy =  0.9428811423771525\n",
      "c1 =  0.0001 ; c2 =  0.01  : accuracy =  0.9470810583788324\n",
      "c1 =  0.0001 ; c2 =  0.1  : accuracy =  0.9454010919781605\n",
      "c1 =  0.001 ; c2 =  0.0001  : accuracy =  0.9399412011759765\n",
      "c1 =  0.001 ; c2 =  0.001  : accuracy =  0.9445611087778244\n",
      "c1 =  0.001 ; c2 =  0.01  : accuracy =  0.9475010499790004\n",
      "c1 =  0.001 ; c2 =  0.1  : accuracy =  0.9449811003779924\n",
      "c1 =  0.01 ; c2 =  0.0001  : accuracy =  0.9487610247795044\n",
      "c1 =  0.01 ; c2 =  0.001  : accuracy =  0.9479210415791685\n",
      "c1 =  0.01 ; c2 =  0.01  : accuracy =  0.9470810583788324\n",
      "c1 =  0.01 ; c2 =  0.1  : accuracy =  0.9449811003779924\n",
      "c1 =  0.1 ; c2 =  0.0001  : accuracy =  0.9470810583788324\n",
      "c1 =  0.1 ; c2 =  0.001  : accuracy =  0.9458210835783284\n",
      "c1 =  0.1 ; c2 =  0.01  : accuracy =  0.9470810583788324\n",
      "c1 =  0.1 ; c2 =  0.1  : accuracy =  0.9475010499790004\n"
     ]
    }
   ],
   "source": [
    "c1_list=[0.0001,0.001,0.01,0.1]\n",
    "c2_list=[0.0001,0.001,0.01,0.1]\n",
    "for c1 in c1_list:\n",
    "    for c2 in c2_list:\n",
    "        # running test with ALL features\n",
    "        acc,_,_=crf_feature_test(None,c1=c1,c2=c2,limit=10000)\n",
    "        print(\"c1 = \",c1,\"; c2 = \",c2,\" : accuracy = \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Thus, although variation in accuracy scores is quite small, we nevertheless proceed with the combination that gave us the best performance :\n",
    "\n",
    "   **c1 = 0.01**\n",
    "\n",
    "   **c2 = 0.0001**\n",
    "   \n",
    "***\n",
    "\n",
    "   \n",
    "### Creating and testing a full-fledged model with all features and the c1, c2 values as found above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suyash/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc_final, y_test, y_pred=crf_feature_test(None,c1=0.01,c2=0.0001,limit=len(sents_train))\n",
    "f1_score=metrics.flat_f1_score(y_test,y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final accuracy and f-score for CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9509121303766002\n",
      "accuracy:  0.9542209155816883\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .       1.00      1.00      1.00       334\n",
      "        ADJ       0.87      0.89      0.88       140\n",
      "        ADP       0.95      0.97      0.96       283\n",
      "        ADV       0.88      0.88      0.88       124\n",
      "       CONJ       1.00      0.99      0.99        84\n",
      "        DET       1.00      1.00      1.00       295\n",
      "       NOUN       0.92      0.96      0.94       483\n",
      "        NUM       0.95      0.95      0.95        21\n",
      "       PRON       1.00      0.99      1.00       160\n",
      "        PRT       0.90      0.89      0.89        70\n",
      "       VERB       0.97      0.94      0.95       370\n",
      "          X       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suyash/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score)\n",
    "print(\"accuracy: \",acc_final)\n",
    "print(metrics.flat_classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Final Results:\n",
    "\n",
    "- ### HMM accuracy on 100 test samples : 93.33%\n",
    "- ### CRF accuracy on 100 test samples : 95.422% ; F-score = 0.9509"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
